# ğŸ—£ï¸ğŸ’¾  Interface dâ€™interrogation SQL en langage naturel (ICV â†’ SQL)

**Objectif.** Construire un systÃ¨me qui comprend des requÃªtes en **langage naturel (FR)** et les **traduit en SQL** pour interroger une base de films : extraction **Intentionâ€“Conceptsâ€“Valeurs (ICV)**, **prÃ©diction dâ€™intentions** (*SELECT* / *WHERE*), **gÃ©nÃ©ration** puis **exÃ©cution** de la requÃªte SQL. :contentReference[oaicite:0]{index=0} :contentReference[oaicite:1]{index=1}

---

## ğŸ“Œ Vue dâ€™ensemble du systÃ¨me

- **Lexique automatique** extrait depuis `base_films_500.csv` (acteurs, rÃ©alisateur, genre, annÃ©e, titre) pour reconnaÃ®tre les **valeurs** des **concepts**. :contentReference[oaicite:2]{index=2}  
- **Analyse lexicale** : dÃ©tection (concept, valeur) dans la requÃªte ; gestion multi-acteurs et annÃ©es â†’ `BETWEEN` si deux annÃ©es dÃ©tectÃ©es. :contentReference[oaicite:3]{index=3}  
- **Classification des intentions**
  - **SELECT** : pipeline `CountVectorizer + Perceptron` pour prÃ©dire les colonnes Ã  retourner. :contentReference[oaicite:4]{index=4}
  - **WHERE** : **rÃ¨gles** (acteur(s), genre, rÃ©alisateur, annÃ©e, `BETWEEN`). :contentReference[oaicite:5]{index=5}  
- **GÃ©nÃ©ration & exÃ©cution SQL** via **SQLite** (base en mÃ©moire) ; restitution des rÃ©sultats. :contentReference[oaicite:6]{index=6}

---

## ğŸ§ª RÃ©sultats (Ã©valuations)

### Quantitatif (corpus fournis)
- **SQL gÃ©nÃ©rÃ©e vs SQL de rÃ©fÃ©rence** (normalisÃ©e avant comparaison) : **4809 / 6762** â†’ **71,12 %**. :contentReference[oaicite:7]{index=7}  
- **Exactitude du rÃ©sultat (queryâ†’value)** sur `queries_french_para_eval_values.json` : **1691 / 1695** â†’ **99,76 %**. :contentReference[oaicite:8]{index=8}  
- Consignes dâ€™Ã©valuation et liens des corpus dâ€™Ã©val : voir Ã©noncÃ©. :contentReference[oaicite:9]{index=9}

### Qualitatif (20 requÃªtes rÃ©elles)
- Protocole demandÃ© : 20 requÃªtes, notation {0,1,3}, comparaison avec le quantitatif + analyse dâ€™erreurs. :contentReference[oaicite:10]{index=10}

**Conclusion.** Le systÃ¨me est robuste sur requÃªtes bien formÃ©es (forte exactitude des rÃ©ponses), plus sensible aux fautes/variations libres ; pistes : correction orthographique lÃ©gÃ¨re, rÃ¨gle `titre LIKE '%mot%'`, amÃ©lioration des cas abstraits. :contentReference[oaicite:11]{index=11}

---

## ğŸ—‚ï¸ DonnÃ©es & corpus

- **Base films** : `base_films_500.csv` (source indiquÃ©e dans lâ€™Ã©noncÃ©). :contentReference[oaicite:12]{index=12}  
- **Apprentissage / paraphrases** : `queries_french_para.json` (ICV, FR + paraphrases). :contentReference[oaicite:13]{index=13}  
- **Ã‰valuation (inclus dans ce dÃ©pÃ´t)**  
  - `data/queries_french_para_eval.json` â€” requÃªtes FR + **SQL de rÃ©fÃ©rence**. :contentReference[oaicite:14]{index=14}  
  - `data/queries_french_para_eval_values.json` â€” **paires (query â†’ value)** pour Ã©valuer la **rÃ©ponse**, pas seulement la SQL. (inclus)  

> Les chemins vers `base_films_500.csv` et le corpus dâ€™apprentissage sont paramÃ©trables dans le notebook/script.



